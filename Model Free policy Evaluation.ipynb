{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from gridworld import GridWorld\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "world=\\\n",
    "    \"\"\"\n",
    "    wwwwwwwww\n",
    "    wa      w\n",
    "    w    ww w\n",
    "    www     w\n",
    "    w    w  w\n",
    "    w      gw\n",
    "    wwwwwwwww\n",
    "    \"\"\"\n",
    "env=GridWorld(world)\n",
    "env._max_epi_step=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monti-Carlo policy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_episode(policy):\n",
    "    l=[]\n",
    "    curr_state=env.reset()\n",
    "    done=False\n",
    "    while not done:\n",
    "        a=policy[curr_state]\n",
    "        next_state,reward,done,info=env.step(a)\n",
    "        l.append((curr_state,reward))\n",
    "        curr_state=next_state\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_returns_from_episode(episode):\n",
    "    G=[]\n",
    "    for i,(s,r) in enumerate(episode):\n",
    "        summ=r\n",
    "        future=episode[i+1:]\n",
    "        for j,(sn,rn) in enumerate(future):\n",
    "            summ=summ+(0.99**(j+1))*rn\n",
    "        G.append((s,summ))\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy=np.random.choice([0,1,2,3],size=29) #policy\n",
    "experience=[get_returns_from_episode(get_episode(policy)) for i in range(1000)] #experience\n",
    "G_total=np.zeros(env.state_count)  #G_summ\n",
    "N_total=np.zeros(env.state_count)  #state seen count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prasenjit/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in true_divide\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "for epi in experience:\n",
    "    seen=[]\n",
    "    for s,G in epi:\n",
    "        if s not in seen:\n",
    "            G_total[s]+=G\n",
    "            N_total[s]+=1\n",
    "            seen.append(s)\n",
    "\n",
    "V=G_total/N_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-62.2347953 , -53.64030297, -53.78894552, -43.88601096,\n",
       "       -43.18154378, -36.72242941, -30.28091744, -61.6506605 ,\n",
       "       -55.79177446, -54.4736039 , -40.80881467, -24.73450669,\n",
       "       -38.6257125 , -22.39663307, -20.01122497, -10.79224115,\n",
       "         1.47759457, -28.82536221, -30.51095084, -39.04643804,\n",
       "       -31.33381475, -10.95348652,   6.11248325, -29.5822549 ,\n",
       "       -33.41781299, -38.25521156, -31.60282777, -27.61797959,\n",
       "       -12.40672958,          nan])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy=np.random.choice([0,1,2,3],size=29) #policy\n",
    "experience=[get_returns_from_episode(get_episode(policy)) for i in range(1000)] #experience\n",
    "V=np.zeros(env.state_count)  #G_summ\n",
    "N=np.zeros(env.state_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epi in experience:\n",
    "    seen=[]\n",
    "    for s,G in epi:\n",
    "        if s not in seen:\n",
    "            V[s]=V[s]+(1/(N[s]+1))*(G-V[s])\n",
    "            N[s]+=1\n",
    "            seen.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.04529355e+01, -5.98937009e+01, -5.05890224e+01, -3.89393380e+01,\n",
       "       -3.80474855e+01, -3.71947202e+01, -3.17964901e+01, -5.05352463e+01,\n",
       "       -5.93411788e+01, -4.52279613e+01, -4.28441891e+01, -2.52176019e+01,\n",
       "       -3.36077825e+01, -2.97468482e+01, -2.48684994e+01, -1.43355095e+01,\n",
       "       -1.49299591e+01, -1.34508385e+01, -1.57946417e+01, -2.65228347e+01,\n",
       "        6.07161603e-03, -9.13763015e+00,  7.93439025e+00, -6.60409046e+00,\n",
       "       -4.57216318e+00, -5.22174765e-01,  3.26629342e+00,  6.60444817e+00,\n",
       "        8.21178874e+00,  0.00000000e+00])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TD Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tuple(policy):\n",
    "    curr_state=env.reset()\n",
    "    while True:\n",
    "        a=policy[curr_state]\n",
    "        next_state,reward,done,info=env.step(a)\n",
    "        yield(curr_state,reward,next_state)\n",
    "        if done:\n",
    "            curr_state=env.reset()\n",
    "        else:\n",
    "            curr_state=next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen=get_tuple(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.001\n",
    "gamma=0.99\n",
    "v=np.zeros(env.state_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in range(100000):\n",
    "    s,r,s_prime=next(gen)\n",
    "    v[s]=v[s]+alpha*((r+gamma*v[s_prime])-v[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
